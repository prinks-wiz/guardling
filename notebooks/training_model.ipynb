{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7176a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Data handling & exploration\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903cb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"toxigen/toxigen-data\", \"annotated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d196425",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3acf7902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target_group</th>\n",
       "      <th>factual?</th>\n",
       "      <th>ingroup_effect</th>\n",
       "      <th>lewd</th>\n",
       "      <th>framing</th>\n",
       "      <th>predicted_group</th>\n",
       "      <th>stereotyping</th>\n",
       "      <th>intent</th>\n",
       "      <th>toxicity_ai</th>\n",
       "      <th>toxicity_human</th>\n",
       "      <th>predicted_author</th>\n",
       "      <th>actual_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>put your pronouns on your iphone keyboards.</td>\n",
       "      <td>lgbtq</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>the text indirectly references lgbtq</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7487</th>\n",
       "      <td>the world's largest rainbow flag was unfurled ...</td>\n",
       "      <td>lgbtq</td>\n",
       "      <td>factual</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>['the text directly references lgbtq', 'the te...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>america is not a melting pot, it is more like ...</td>\n",
       "      <td>latino</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>solution</td>\n",
       "      <td>['it is unclear who is referenced', 'it is unc...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>cbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>native americans are usually left out of socia...</td>\n",
       "      <td>native_american</td>\n",
       "      <td>factual</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>cause</td>\n",
       "      <td>the text directly references native_american</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>for all the middle easterners here, we may dis...</td>\n",
       "      <td>muslim</td>\n",
       "      <td>neither factual nor opinion</td>\n",
       "      <td>doesn't use in-group language</td>\n",
       "      <td>doesn't contain lewd content</td>\n",
       "      <td>disagreement</td>\n",
       "      <td>['the text references conservatives', 'it is u...</td>\n",
       "      <td>doesn't use positive stereotyping</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>human</td>\n",
       "      <td>topk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     target_group  \\\n",
       "3277        put your pronouns on your iphone keyboards.            lgbtq   \n",
       "7487  the world's largest rainbow flag was unfurled ...            lgbtq   \n",
       "2429  america is not a melting pot, it is more like ...           latino   \n",
       "2474  native americans are usually left out of socia...  native_american   \n",
       "4776  for all the middle easterners here, we may dis...           muslim   \n",
       "\n",
       "                         factual?                 ingroup_effect  \\\n",
       "3277  neither factual nor opinion  doesn't use in-group language   \n",
       "7487                      factual  doesn't use in-group language   \n",
       "2429                 disagreement  doesn't use in-group language   \n",
       "2474                      factual  doesn't use in-group language   \n",
       "4776  neither factual nor opinion  doesn't use in-group language   \n",
       "\n",
       "                              lewd       framing  \\\n",
       "3277  doesn't contain lewd content  disagreement   \n",
       "7487  doesn't contain lewd content  disagreement   \n",
       "2429  doesn't contain lewd content      solution   \n",
       "2474  doesn't contain lewd content         cause   \n",
       "4776  doesn't contain lewd content  disagreement   \n",
       "\n",
       "                                        predicted_group  \\\n",
       "3277               the text indirectly references lgbtq   \n",
       "7487  ['the text directly references lgbtq', 'the te...   \n",
       "2429  ['it is unclear who is referenced', 'it is unc...   \n",
       "2474       the text directly references native_american   \n",
       "4776  ['the text references conservatives', 'it is u...   \n",
       "\n",
       "                           stereotyping    intent  toxicity_ai  \\\n",
       "3277  doesn't use positive stereotyping  3.000000     2.333333   \n",
       "7487  doesn't use positive stereotyping  1.000000     1.000000   \n",
       "2429  doesn't use positive stereotyping  1.000000     1.000000   \n",
       "2474  doesn't use positive stereotyping  1.666667     2.000000   \n",
       "4776  doesn't use positive stereotyping  3.000000     3.000000   \n",
       "\n",
       "      toxicity_human predicted_author actual_method  \n",
       "3277        2.666667            human          topk  \n",
       "7487        1.000000            human          topk  \n",
       "2429        1.000000            human           cbs  \n",
       "2474        2.000000            human          topk  \n",
       "4776        3.000000            human          topk  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(ds[\"train\"]) # Toxigen is stored in the train split of a huggingface dataset\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15ca3706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8960, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1155dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(940, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c15e5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['asian', 'mexican', 'muslim', 'physical_dis', 'jewish',\n",
       "       'native_american', 'lgbtq', 'women', 'middle_east', 'chinese',\n",
       "       'mental_dis', 'latino', 'black'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"target_group\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56b481c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'target_group', 'factual?', 'ingroup_effect', 'lewd', 'framing',\n",
       "       'predicted_group', 'stereotyping', 'intent', 'toxicity_ai',\n",
       "       'toxicity_human', 'predicted_author', 'actual_method'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210e5290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guarling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
